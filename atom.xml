<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[TextstÃ¼ckchen]]></title>
  <link href="http://www.dbrunner.de/atom.xml" rel="self"/>
  <link href="http://www.dbrunner.de/"/>
  <updated>2015-12-20T12:26:18+00:00</updated>
  <id>http://www.dbrunner.de/</id>
  <author>
    <name><![CDATA[Daniel Brunner]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[I played with CHICKEN Scheme, Docker and Alpine Linux]]></title>
    <link href="http://www.dbrunner.de/blog/2015/12/19/i-played-with-chicken-scheme/"/>
    <updated>2015-12-19T17:54:50+00:00</updated>
    <id>http://www.dbrunner.de/blog/2015/12/19/i-played-with-chicken-scheme</id>
    <content type="html"><![CDATA[<p>I am looking forward to meet LISP people at the
<a href="https://events.ccc.de/congress/2015/wiki/Main_Page">32c3&rsquo;s</a> <a href="https://events.ccc.de/congress/2015/wiki/Assembly:The_%28un%29employed_schemers_%26_lispers_guild">LISP assembly</a>. The last days I played a bit with different Scheme
implementations including
<a href="http://call-cc.org">CHICKEN scheme</a>. The main feature of CHICKEN is
that it compiles the Scheme code to C and then creates dynamic
libraries and binaries with the C compiler. I thought that combining
these binaries with a minimal Docker container could give me a very
small deployment. So here are my steps:</p>

<h2>Choosing Alpine Linux as a &ldquo;small&rdquo; Linux</h2>

<p>The smallest Linux image for Docker is undoubtly busybox with a size
of about 2.489 MB. But busybox lacks a package manager which makes
installing software painful. Therefore I have chosen
<a href="http://alpinelinux.org">Alpine Linux</a> which comes with package
manager and it&rsquo;s image&rsquo;s size is about 5.234 MB. That&rsquo;s double the
size of the busybox image but still quite small compared to the Ubuntu
image which is about 266 MB.</p>

<h2>Creating a Docker container with CHICKEN</h2>

<p>Alpine Linux comes with the <a href="http://www.muscl-libc.org">musl libc</a> and
I thought it would be best to compile all the CHICKEN stuff with that
libc. Therefore I created a Docker container with gcc and all the
other stuff with this Dockerfile
(<a href="https://github.com/krrrcks/chicken-docker-alpine">Github repository</a>):</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>FROM alpine:3.2
</span><span class='line'>
</span><span class='line'>RUN apk update && apk add make gcc musl-dev 
</span><span class='line'>RUN wget -O - http://code.call-cc.org/releases/4.10.0/chicken-4.10.0.tar.gz | tar xz
</span><span class='line'>
</span><span class='line'>WORKDIR /chicken-4.10.0
</span><span class='line'>
</span><span class='line'>RUN make PLATFORM=linux && make PLATFORM=linux install
</span><span class='line'>
</span><span class='line'>RUN rm -fr /chicken-4.10.0 
</span><span class='line'>
</span><span class='line'>WORKDIR /
</span><span class='line'>
</span><span class='line'>CMD ["csi"]</span></code></pre></td></tr></table></div></figure>


<p>This image is quite big (about 161.7 MB) and is available for download
at the <a href="https://hub.docker.com/r/krrrcks/chicken-alpine/">Docker Hub</a>.</p>

<h2>Compiling some CHICKEN code</h2>

<p>For testing purposes I wanted a minimal web server running in the Alpine
Linux image. Therefore I looked through the
<a href="http://wiki.call-cc.org/chicken-projects/egg-index-4.html">egg index</a>
and found <a href="http://wiki.call-cc.org/eggref/4/spiffy">spiffy</a>. I fired
up the <code>chicken-alpine</code> container (but I used <code>ash</code> as command instead
of the <code>csi</code> Scheme interpreter) and created a small web server that
serves some static pages. I wrote a <code>main.scm</code>:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>(use spiffy)
</span><span class='line'>(start-server)</span></code></pre></td></tr></table></div></figure>


<p>and added some static pages to a <code>./web</code> sub-directory. Then
everything had to be compiled and prepared for deployment:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>chicken-install spiffy
</span><span class='line'>csc -deploy main.scm
</span><span class='line'>chicken-install -deploy -p $PWD/main spiffy</span></code></pre></td></tr></table></div></figure>


<h2>Deploy in a fresh Alpine Linux image</h2>

<p>After the compilation I copied the <code>main</code> and <code>web</code> directories on my
host machine using <code>docker cp</code> and created the following Dockerfile:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>FROM alpine:3.2
</span><span class='line'>
</span><span class='line'>ADD main /main
</span><span class='line'>ADD web main/web
</span><span class='line'>WORKDIR main
</span><span class='line'>
</span><span class='line'>CMD /main/main</span></code></pre></td></tr></table></div></figure>


<p></p>

<p>and let <code>docker build -t krrrcks/spiffy-test .</code> do the job. The size
of the resulting image is about 12.37 MB and that&rsquo;s pretty small. I
uploaded that image to the
<a href="https://hub.docker.com/r/krrrcks/spiffy-test/">Docker Hub</a> as well.</p>

<p>To serve the pages I did a <code>docker run -d -p 8080:8080 krrrcks/spiffy-test</code>
(spiffy listens on port 8080 in the default install) and browsed my
static pages.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How to use GET Bucket location on Amazon S3 with Racket]]></title>
    <link href="http://www.dbrunner.de/blog/2015/09/04/how-to-use-getbucketlocation-on-amazon-s3-with-racket/"/>
    <updated>2015-09-04T07:23:43+00:00</updated>
    <id>http://www.dbrunner.de/blog/2015/09/04/how-to-use-getbucketlocation-on-amazon-s3-with-racket</id>
    <content type="html"><![CDATA[<p>In <a href="http://www.racket-lang.org">Racket</a> I want to iterate over my
buckets in Amazon S3. They are located in different regions. So how do
I get my bucket&rsquo;s location/region? In the API Reference there is a
call
<a href="http://docs.aws.amazon.com/AmazonS3/latest/API/RESTBucketGETlocation.html">GET Bucket location</a>. I
use
<a href="https://github.com/greghendershott/aws">Greg&rsquo;s AWS library for Racket</a>
and this library authenticates its calls with
<a href="http://docs.aws.amazon.com/AmazonS3/latest/API/sigv4-auth-using-authorization-header.html">signature version V4</a>. But
V4 requires the user to know the <em>region</em> to correctly sign the
request. So I need to know the region to ask Amazon S3 for the region
where the bucket is located. Otherwise Amazon S3 responds with an
error:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&lt;?xml version="1.0" encoding="UTF-8"?&gt;
</span><span class='line'>&lt;Error&gt;
</span><span class='line'> &lt;Code&gt;AuthorizationHeaderMalformed&lt;/Code&gt;
</span><span class='line'> &lt;Message&gt;The authorization header is malformed; the region 'us-east-1'
</span><span class='line'>is wrong; expecting 'eu-central-1'&lt;/Message&gt;
</span><span class='line'> &lt;Region&gt;eu-central-1&lt;/Region&gt;
</span><span class='line'> &lt;RequestId&gt;XXXX&lt;/RequestId&gt;
</span><span class='line'> &lt;HostId&gt;XXXX&gt;
</span><span class='line'>&lt;/Error&gt;</span></code></pre></td></tr></table></div></figure>


<p>After some search on the net I found a
<a href="http://stackoverflow.com/questions/27091816/retrieve-buckets-objects-without-knowing-buckets-region-with-aws-s3-rest-api">post on Stackoverflow</a>
that helped to solve that issue: If I use the URL format (instead of
the normally used virtual host format) I could get the location of
any bucket. Every region responds with a <em>LocationConstraint</em> answer.</p>

<p>Therefore a code snippet for Racket could be:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>(define (get-bucket-location bucket)
</span><span class='line'>  (parameterize
</span><span class='line'>      ([s3-path-requests? #t])
</span><span class='line'>    (define xpr (get/proc (string-append bucket "/?location") read-entity/xexpr))
</span><span class='line'>    (and (list? xpr)
</span><span class='line'>         (= (length xpr) 3)
</span><span class='line'>         (third xpr))))</span></code></pre></td></tr></table></div></figure>


<p>For example:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&gt; (get-bucket-location "my-bucket-somewhere")
</span><span class='line'>"eu-central-1"</span></code></pre></td></tr></table></div></figure>


<p>PS: I think official Amazon S3 documentation could be a bit more verbose on
the issues with GetBucketLocation and signature V4.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How to run Racket on the Raspberry Pi 2]]></title>
    <link href="http://www.dbrunner.de/blog/2015/08/27/how-to-run-racket-on-the-raspberry-pi-2/"/>
    <updated>2015-08-27T13:25:45+00:00</updated>
    <id>http://www.dbrunner.de/blog/2015/08/27/how-to-run-racket-on-the-raspberry-pi-2</id>
    <content type="html"><![CDATA[<p>I got a
<a href="https://www.raspberrypi.org/products/raspberry-pi-2-model-b/">Raspberry Pi 2 Model B</a>
to play with. I used Raspbian image as operating system.  I was
wondering how difficult it is to get Racket running on the Raspberry
Pi. I downloaded the
<a href="http://mirror.racket-lang.org/installers/6.2.1/racket-6.2.1-src-builtpkgs.tgz">Unix source + built packages</a>
tarball from <a href="http://racket-lang.org">Racket&rsquo;s homepage</a> because I
only wanted to compile the core of Racket. After unpacking the tarball
I was suprised that the instructions were quite short:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>From this directory (where the `configure' file is), run the following
</span><span class='line'>commands:
</span><span class='line'>
</span><span class='line'>  mkdir build
</span><span class='line'>  cd build
</span><span class='line'>  ../configure
</span><span class='line'>  make
</span><span class='line'>  make install</span></code></pre></td></tr></table></div></figure>


<p>Between <code>make</code> and <code>make install</code> I had to wait for about 40 minutes
but then everything was fine and I could even use DrRacket on the
Raspberry Pi:</p>

<p><img src="http://www.dbrunner.de/img/2015-08-27-racket-pi.png" alt="DrRacket on Raspberry Pi" /></p>

<p>Very nice and easy to get Racket running on ARM.</p>

<p>PS: Because the Raspberry Pi 2 Model B has an ARMv7 processor the
binary runs on my Jolla smart phone as well.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Running Racket on AWS Lambda]]></title>
    <link href="http://www.dbrunner.de/blog/2015/08/27/running-racket-on-aws-lambda/"/>
    <updated>2015-08-27T12:46:57+00:00</updated>
    <id>http://www.dbrunner.de/blog/2015/08/27/running-racket-on-aws-lambda</id>
    <content type="html"><![CDATA[<p>I started to use AWS for some projects recently. But I only use few of
their services. From time to time I look into some of there services
and wonder if they are useful for my tasks. I looked into
<a href="http://aws.amazon.com/lambda">AWS Lambda</a>, &ldquo;&hellip; a compute service
that runs your code in response to events and automatically manages
the compute resources for you, making it easy to build applications
that respond quickly to new information.&rdquo; Nowadays these &ldquo;lambda
functions&rdquo; could be written in NodeJS or Java. When I was looking for
a roadmap of the supported languages I found an interesting
<a href="http://blog.0x82.com/2014/11/24/aws-lambda-functions-in-go/">blog post</a>
by <a href="https://www.twitter.com/rubenfonseca">Ruben Fonseca</a>. He explaind
how to run Go code on AWS Lambda.</p>

<p>I tried the same with <a href="http://racket-lang.org">Racket</a> and wrote a
short Racket programm <code>test.rkt</code>:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>#lang racket/base
</span><span class='line'>
</span><span class='line'>(display (format "Hello from Racket, args: ~a~%" (current-command-line-arguments)))</span></code></pre></td></tr></table></div></figure>


<p>Then I used <code>raco</code> to create a binary <code>test</code>:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>raco exe --orig-exe test.rkt</span></code></pre></td></tr></table></div></figure>


<p>I took the NodeJS wrapper from Ruben&rsquo;s blog post and put it in a file
<code>main.js</code>:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>var child_process = require('child_process');
</span><span class='line'>
</span><span class='line'>exports.handler = function(event, context) {
</span><span class='line'>  var proc = child_process.spawn('./test', [ JSON.stringify(event) ], { stdio: 'inherit' });
</span><span class='line'>
</span><span class='line'>  proc.on('close', function(code) {
</span><span class='line'>    if(code !== 0) {
</span><span class='line'>      return context.done(new Error("Process exited with non-zero status code"));
</span><span class='line'>    }
</span><span class='line'>
</span><span class='line'>    context.done(null);
</span><span class='line'>  });
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>Then I put both files in a zip archive, created a new AWS Lambda
function, uploaded the zip file and invoked the function:</p>

<p><img src="http://www.dbrunner.de/img/2015-08-27-racket-aws-lambda.png" alt="Invocation of AWS Lambda function" /></p>

<p>Fine!</p>

<p>PS: Only question is: When is AWS Lambda coming to the region
<code>eu-central-1</code>, located in Frankfurt?</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Lisp und ich]]></title>
    <link href="http://www.dbrunner.de/blog/2015/08/27/lisp-und-ich/"/>
    <updated>2015-08-27T10:57:45+00:00</updated>
    <id>http://www.dbrunner.de/blog/2015/08/27/lisp-und-ich</id>
    <content type="html"><![CDATA[<p>Dieser Beitrag ist kurzer Hintergrund fÃ¼r meine bisherigen und
zukÃ¼nftigen BeitrÃ¤ge zur Programmierung und
Software-Entiwcklung. Eigentlich ist es eher ein <em>Disclaimer</em>, denn
ich habe das gar nicht professionell gelernt. Ich habe ein
sozialwissenschaftliches Fach studiert und meine Kenntnisse aus dem
Bereich der Programmierung entstammen im Wesentlichen meiner Schul-
und Studienzeit und sehr viel autodidaktes Lernen. Insofern ist aller
Code von mir mit einer gewissen Vorsicht zu genieÃen; mÃ¶glicherweise
ist das nicht immer die beste und schÃ¶nste Variante ein Problem zu
lÃ¶sen.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Der Rundfunkrat des hr Ã¼bt den Diskurs]]></title>
    <link href="http://www.dbrunner.de/blog/2015/02/17/der-rundfunkrat-des-hr-ubt-den-diskurs/"/>
    <updated>2015-02-17T11:44:35+00:00</updated>
    <id>http://www.dbrunner.de/blog/2015/02/17/der-rundfunkrat-des-hr-ubt-den-diskurs</id>
    <content type="html"><![CDATA[<p>Am 15. Dezember 2014 hat der
<a href="http://www.bundesfinanzministerium.de/Web/DE/Ministerium/Geschaeftsbereich/Wissenschaftlicher_Beirat/wissenschaftlicher_beirat.html">Wissenschaftliche Beirat des Bundesministeriums des Finanzen</a>
ein Gutachten zu &ldquo;Ãffentlich-rechtliche Medien - Aufgabe und
Finanzierung&rdquo;
<a href="http://www.bundesfinanzministerium.de/Content/DE/Downloads/Broschueren_Bestellservice/2014-12-15-gutachten-medien.pdf?__blob=publicationFile&amp;v=9">verÃ¶ffentlicht</a>.</p>

<p>Der Inhalt wollte dem einen oder anderen Vertreter der
Ã¶ffentlich-rechtlichen Medien nicht schmecken. So haben sich der Runkfunkrat
und der Verwaltungsrat des Hessischen Rundfunks &ldquo;ausfÃ¼hrlich&rdquo; mit dem
Gutachten und einer Stellungnahme des &ldquo;hr-Justitiars&rdquo; befasst und
einen &ldquo;einstimmigen Beschluss&rdquo; hierzu
<a href="http://www.hr-online.de/website/extern/rundfunkrat/download.jsp?key=standard_document_54315171&amp;row=0&amp;rubrik=62561">gefasst</a>.</p>

<p>Ich mÃ¶chte nun nicht auf sÃ¤mtliche Aspekte des Gutachtens und was
dafÃ¼r oder dagegen spricht eingehen. Allerdings hat mich das eine oder
andere in dem &ldquo;Beschluss&rdquo; der hr-Gremien etwas stutzig
gemacht. Es heiÃt dort gleich zu Beginn:</p>

<blockquote><p>&ldquo;1. Der Rundfunkrat und der Verwaltungsrat kritisieren, dass sich ein
   fÃ¼r Rundfunktfragen unstreitig unzustÃ¤ndiges Gremium ein Papier
   verÃ¶ffentlicht hat, das lÃ¤ngst Ã¼berholte Ã¶konomische Positionen
   wieder aufleben lÃ¤sst und Auffassungen vertritt, die sich weder
   Ã¶konomisch noch rechtlich halten lassen.&rdquo;</p></blockquote>

<p>In Deutschland hat sich neben der Wirtschaftstheorie und
Wirtschaftspolitik ein eigenes Gebiet der &ldquo;Finanzwissenschaft&rdquo; als
Lehre von den Ã¶ffentlichen Haushalten, der Besteuerung, der
Staatsausgaben, der Ã¶ffentlichen Schuld, der StaatstÃ¤tigkeit
etc. herausgebildet. Einige Vertreter dieses Faches sind Mitglieder
des Wissenschaftlichen Beirats beim Bundesministerium der Finanzen.</p>

<p>Eine der ersten Fragen in der Finanzwissenschaft, die man sich
bspw. in der universitÃ¤ren Ausbildung stellt, ist: &ldquo;Was gehÃ¶rt
eigentlich zum &lsquo;Staat&rsquo;?&rdquo; Mitunter zuerst fallen einem die
GebietskÃ¶rperschaften (Bund, LÃ¤nder und Gemeinden) und ihre Haushalte
ein. Daneben spielen aber auch Ã¶ffentlich-rechtliche Institutionen
eine bedeutsame Rolle, die man mit dem Begriff der &ldquo;Parafisken&rdquo;
bezeichnet, sie erfÃ¼llen Ã¶ffentliche Aufgaben und finanzieren sich in
der Regel Ã¼ber Zwangsabgaben. Hierzu zÃ¤hlt man beispielsweise die
Sozialversicherungen, aber auch Kammern, soweit sie Ã¶ffentliche
Aufgaben wahrnehmen. Auch sie sind Gegenstand der
Finanzwissenschaft. In meinem Exemplar von Zimmermann/Henke,
Finanzwissenschaft, 7. Auflage, 1994 sind einige AusfÃ¼hrungen zu den
Parafisken auf den Seiten 8 bis 11 zu finden.</p>

<p>Und hierzu gehÃ¶ren aus diesem Blickwinkel unstreitig auch die
Institutionen des Ã¶ffentlich-rechtlichen Rundfunks. Eine etwas
ausfÃ¼hrlichere Darstellung zu den Parafisken findet sich in einem
<a href="http://www.diw.de/sixcms/detail.php?id=diw_01.c.41304.de">Gutachten des DIW Berlin von C. Katharina SpieÃ</a>
aus dem Jahr 2014 (das allerdings nicht den Rundfunk, sondern
familienpolitische Leistungen zum wesentlichen Inhalt hat) in den
Kapiteln 2 bis 3, fÃ¼r den Ã¶ffentlich-rechtlichen Rundfunk im Abschnitt
3.3.</p>

<p>Wenn nun die Ã¶ffentlich-rechtlichen Rundfunkanstalten Parafisken sind,
die Parafisken zum Gegenstand der Finanzwissenschaft gehÃ¶ren, dann
wÃ¤re es meines Erachtens strÃ¤flich, wÃ¼rde sich der Wissenschaftliche
Beirat beim BMF nicht damit befassen.</p>

<p>Insofern halte ich die Behauptung, der Beirat sei &ldquo;unstreitig
unzustÃ¤ndig&rdquo; fÃ¼r falsch und irrefÃ¼hrend.</p>

<p>AuÃerdem beschreibt die
<a href="http://www.bundesfinanzministerium.de/Web/DE/Ministerium/Geschaeftsbereich/Wissenschaftlicher_Beirat/Satzung/satzung.html">Satzung</a>
des Beirates seine Aufgaben recht weit:</p>

<blockquote><p> &ldquo;Â§ 1 Aufgaben des Beirats</p>

<p>Der Beirat soll den Bundesminister der
Finanzen in voller UnabhÃ¤ngigkeit und ehrenamtlich in allen Fragen
der Finanzpolitik beraten.&#8221;</p></blockquote>

<p>Die hr-Gremien haben insgesamt 7 Punkte beschlossen. Obwohl sie in dem
oben zitierten ersten Punkt dem Beirat Auffassungen unterstellen, die
sich ihrer Ansicht nach Ã¶konomisch nicht halten lassen, so finden sich
in den beschlossenen Punkten nahezu keinerlei Ã¶konomische
Entgegenungen:</p>

<ul>
<li>In Punkt 2 werden die unterstellten Marktmechanismen in Bezug auf
den Zeitungsmarkt in Frage gestellt.</li>
<li>In Punkt 3 wird im Kern argumentiert, man hÃ¤tte doch auch das
Angebot des Ã¶ffentlich-rechtlichen Rundfunks beachten sollen.</li>
</ul>


<p>DemgegenÃ¼ber wird bis auf Punkt 2 durchgehend mit
&ldquo;verfassungsrechtlich&rdquo; (kommt als Wort insgesamt 5mal vor) oder dem
&ldquo;Bundesverfassungsgericht&rdquo; (4 Vorkommen, 3mal als
&ldquo;Bundesverfassungsgericht&rdquo; und einmal als &ldquo;hÃ¶chste deutsche Gericht&rdquo;)
argumentiert.</p>

<p>Zum Schutz der hr-Gremien muss man allerdings noch erwÃ¤hnen, dass der
Beirat in seinem Gutachten neben eher finanzpolitischen Ãberlegungen
auch einen Abschnitt Ã¼ber verfassungsrechtliche Perspektiven verfasst
hatte.</p>

<p>Es bleibt aber dabei, dass die hr-Gremien sich bis auf ihren Punkt 2
mit den Ã¶konomischen Fragestellungen aus dem Gutachten eigentlich
nicht recht auseinandersetzen wollen. Dabei wÃ¤re das dringend
nÃ¶tig. Die Auseinandersetzungen um Druckerzeugnisse vs. Rundfunk,
&ldquo;Tagesschau-App&rdquo;, Depublizierung, neuartige RundfunkgerÃ¤te,
etc. machen meines Erachtens deutlich, dass hier ein Austausch von
Argumenten dringend nÃ¶tig wÃ¤re. Hierzu haben die hr-Gremien allerdings
entweder nicht die Kraft oder nicht das Verlangen. Statt dessen werfen
sie dem Wissenschaftlichen Beirat eine Entgleisung vor, wenn sie
schreiben:</p>

<blockquote><p>&ldquo;Das Ignorieren der mittlerweile 50jÃ¤hrigen kontinuierlichen
Rechtsprechung des Bundesverfassungsgerichts zur dualen
Rundfunkordnung &hellip; ist &hellip; nicht nur eine indiskutable Ohrfeige an
das hÃ¶chste deutsche Gericht, &hellip;&rdquo;</p></blockquote>

<p>An diesem Zitat zeigt sich fÃ¼r mich auch, dass ein Austausch von
Argumenten wohl gar nicht gewollt ist. Die Positionen des Beirats werden
mit kernigen Formulierungen belegt: &ldquo;Auffassungen vertritt, die sich weder
Ã¶konomisch noch rechtlich halten lassen&rdquo;, &ldquo;indiskutable Ohrfeige an
das hÃ¶chste deutsche Gericht&rdquo;, &ldquo;mit der Entwicklung der
Rundfunkordnung &hellip; in keiner Weise ernsthaft auseinandergesetzt&rdquo;,
&ldquo;verkennt in erschreckender Weise&rdquo;, &ldquo;vÃ¶llig unverstÃ¤ndlich&rdquo;, &ldquo;vÃ¶llig
abwegig&rdquo;, &ldquo;hat sich keinerlei MÃ¼he gemacht&rdquo;, &ldquo;macht deutlich, wie
wenig sich der Beirat mit den rechtlichen und verfassungsrechtlichen
Fakten befasst hat&rdquo;, &ldquo;vÃ¶llig untauglich&rdquo;, &ldquo;keine Alternative&rdquo; und im
letzten Satz &ldquo;[a]ngesichts der vielfachen Defizite des Papiers kann es
auch nicht den Anspruch erheben, wissenschaftlich zu sein.&rdquo;</p>

<p>Im Ergebnis: In meinen Augen zeigen die hr-Gremien einen oft zu
beobachtender Reflex: Die Gegenseite wird zuerst einmal fÃ¼r nicht
zustÃ¤ndig erklÃ¤rt, anschlieÃend ihre Argumente ignoriert und auf einer
anderen Ebene gegen sie argumentiert. Dies passiert schlussendlich
noch in einem Duktus, der auch keine Antwort mehr erwartet.</p>

<p>Insgesamt doch eher unbefriedigend und nicht von der FÃ¤higkeit zum
Diskurs gekennzeichnet. Vielleicht hÃ¤tte man nicht nur den
hr-Justitiar, sondern auch den hr-Ãkonomen befragen sollen.</p>

<p>PS: Nach wie vor macht mich etwas stutzig, wie
<a href="http://www.hr-online.de/website/extern/rundfunkrat/index.jsp?rubrik=45412&amp;key=standard_document_3728464">Rolf-Dieter Postlep</a>
das hat unterschreiben kÃ¶nnen.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Lexmarks Druckerpatronen-Lizenz]]></title>
    <link href="http://www.dbrunner.de/blog/2015/02/17/lexmarks-druckerpatronen-lizenz/"/>
    <updated>2015-02-17T11:28:02+00:00</updated>
    <id>http://www.dbrunner.de/blog/2015/02/17/lexmarks-druckerpatronen-lizenz</id>
    <content type="html"><![CDATA[<p>Heute benÃ¶tigte ich eine Ersatzpatrone fÃ¼r meinen
Lexmark-Drucker. An der AufreiÃlasche prangen Ausrufezeichen und der
Hinweis: &ldquo;Attention: Updated License Terms&rdquo;.</p>

<p>Lizenzbedingungen? FÃ¼r eine Druckerpatrone? Also mal ein Blick aufs
Kleingedruckte:</p>

<blockquote><p>Bitte vor dem Ãffnnen lesen. Durch das Ãffnen der Verpackung oder
die Verwendung der mitgelieferten patentierten Kassette erklÃ¤ren Sie
sich mit der folgenden Lizenz-Vereinbarung einverstanden. Diese
patentierte Tonerkassette wird zu einem Sonderpreis verkauft und
unterliegt der PatenteinschrÃ¤nkung, dass sie nur einmal verwendet
wird. Nach ihrer erstmaligen Verwendung verpflichten Sie sich, sie
zur Wiederaufbereitung und/oder zum Recylcing nur an Lexmark
zurÃ¼ckzugeben. Die Tonerkassette funktioniert nach der Abgabe einer
bestimmten Tonermenge nicht mehr. Wenn sie ersetzt werden muss, kann
sie noch Resttoner enthalten. Die Kassette ist zusÃ¤tzlich so
konzipiert, dass die Informationen zur KassettenkompatibilitÃ¤t im
Druckerspeicher automatisch aktualisiert werden. Auf diese Weise
kann die Verwendung gefÃ¤lschter Kassetten und/oder bestimmer
Drittprodukte eingeschrÃ¤nkt werden. Durch die Installation der
beiliegenden Kassette gestatten Sie Lexmark, diese Ãnderungen
vorzunehmen. Wenn Sie mit den vorgenannten Bedingungen nicht
einverstanden sind, geben Sie die ungeÃ¶ffnete Verpackung an Ihren
HÃ¤ndler zurÃ¼ck. Nicht im Rahmen dieser Bestimmungen verkaufte
Ersatztonerkassetten sind unter www.lexmark.com erhÃ¤ltlich.</p></blockquote>

<p>Irgendwie ja auch ein bisschen putzig, wie um einen Alltagsgegenstand
wie Toner so ein Bohei gemacht wird. Zwei Gedanken kommen mir da in
den Sinn: 1. Es verfestigt sich mein Eindruck, dass das Patentsystem
recht nahe an kaputt ist. 2. Unternehmen, die so etwas machen, sollten
weniger Geld fÃ¼r Juristen, PatentanwÃ¤lte ausgeben und das Geld eher in
coole Produkte investieren.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Spielt ALBA Berlin nun Handball oder Basketball? Der Sportschau ist es egal]]></title>
    <link href="http://www.dbrunner.de/blog/2015/01/30/sportschau-handball-oder-basketball/"/>
    <updated>2015-01-30T11:32:49+00:00</updated>
    <id>http://www.dbrunner.de/blog/2015/01/30/sportschau-handball-oder-basketball</id>
    <content type="html"><![CDATA[<p>Mit Stand vom 14. Januar 2015 erschien auf der Homepage der
<a href="http://www.sportschau">Sportschau</a> ein
<a href="http://www.sportschau.de/weitere/basketball/eurocup144.html">Artikel</a>
Ã¼ber die Bamberger Basketballer. Darin findet sich ein Satz Ã¼ber die
ALBA Berlin (ebenfalls eine Basketball-Mannschaft):</p>

<blockquote><p>ALBA Berlin dominiert aktuell in der Liga und ist das einzig
verbliebene deutsche Team in der Euro League, der Champions League
des Handballs.</p></blockquote>

<p>Ah! ALBA spielt auch noch Handball? Oder doch nicht? Jedenfalls sollte
da wohl &ldquo;in der Euro League, der Champions League des Basketballs&rdquo;
stehen, denn die
<a href="https://de.wikipedia.org/wiki/ULEB_Euroleague">Euro League</a> ist ein
europÃ¤ischer Wettbewerb von Basketball-Vereinsmannschaften.</p>

<p>Denke ich mir also: &ldquo;Ach, wie lustig, das kann ja mal passieren&rdquo; und
twittere die Sportschau am
<a href="https://twitter.com/Krrrcks/status/555840754858610688">15. Januar 2015</a>
und
<a href="ttps://twitter.com/Krrrcks/status/556751066587734016">18. Januar 2015</a>
mit einem Hinweis auf den Tippfehler an. Beim heutigen DurchblÃ¤ttern
der Sportschau-Seite stieÃ ich erneut auf den Text und der Fehler ist
heute, also am 30. Januar 2015, nach wie vor dort zu sehen:</p>

<p><img src="http://www.dbrunner.de/img/2015-01-30-sportschau.png" alt="Homepage Sportschau" /></p>

<p>Ich meine, man kann sich ja mal vertun, aber dann auf einen
Leserhinweis so gar nichts zu unternehmen, ist der Sportschau eigentlich
nicht wÃ¼rdig.</p>

<p><em>Update:</em> Ich twitterte die Sportschau mit meinem Blog-Post an und
 unmittelbar danach wurde der Fehler
 <a href="https://twitter.com/sportschau/status/561138889776447489">korrigiert.</a>
 Sehr prompte Reaktion.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[3. Docker-Meetup in Frankfurt]]></title>
    <link href="http://www.dbrunner.de/blog/2015/01/18/3-docker-meetup-in-frankfurt/"/>
    <updated>2015-01-18T20:05:35+00:00</updated>
    <id>http://www.dbrunner.de/blog/2015/01/18/3-docker-meetup-in-frankfurt</id>
    <content type="html"><![CDATA[<p>Am 13. Januar 2015  fand in Frankfurt das bereits <a href="http://www.meetup.com/Docker-Frankfurt/events/219160756/">dritte Docker-Meetup</a>
statt, hier einige Notizen von mir dazu.</p>

<h2>Neues zum Them Orchestrierung</h2>

<p><a href="https://www.twitter.com/PRossbach">Peter Rossbach</a> hat in einem
munteren Vortrag einige Neuerungen aus dem &ldquo;Docker Universum&rdquo; zum
Thema Orchestrierung vorgestellt. Unter anderem
<a href="https://github.com/docker/machine">Docker Machine</a>,
<a href="https://github.com/docker/swarm">Docker Swarm</a>, Docker Compose
(ehemals <a href="http://fig.sh">fig.sh</a>, das wohl aufgrund von
Aussprachemehrdeutigkeiten umbenannt wurde) etc. Ein sehr
interessanter Ãberblick, insbesondere da Peter auch die ganzen Sachen
immer mal angefasst und ausprobiert hat. Im Kern scheint es mir jedoch
so zu sein, als wÃ¤re die Frage nach &ldquo;Was nimmt man am besten, um
Docker auf einer oder mehreren Maschinen im Produktivbetrieb zu
nutzen?&rdquo; noch recht in Bewegung. FÃ¼r mich kristallisiert sich fÃ¼r
meine AnwendungsfÃ¤lle da bisher noch keine Ã¼berzeugende LÃ¶sung
heraus. Was ich jedoch einmal testen werde ist das fig.sh bzw. Docker
Compose, da man damit eigentlich sehr schÃ¶n in einem YAML-Dokument
mehrere Container und ihre AbhÃ¤ngigkeiten darstellen kann.</p>

<h2>Docker Linking</h2>

<p><a href="http://linsenraum.de">Erkan Yanar</a> hat in einem Einsteigervortrag die
Grundlagen von Links zwischen Containern vorgestellt. Hier scheint die
Entwicklung auch noch in Bewegung zu sein, insbesondere Links Ã¼ber
mehrere Hosts hinweg scheinen doch noch nicht so ganz einfach
handzuhaben zu sein (vorgestellt wurden
<a href="https://github.com/SvenDowideit/dockerfiles/blob/master/ambassador/Dockerfile">Ambassador-AnsÃ¤tze</a>
mit <a href="http://www.dest-unreach.org/socat/">socat</a> und anderes).</p>

<p>Besonders erhellend fand ich den Hinweis, dass ab Docker Version 1.3
nun bei Links zwischen den Containern die <code>/etc/hosts</code> auch nach
Neustarts von gelinkten Containern immer deren richtige IP-Adresse
erhÃ¤lt, wohingegen die Umgebungsvariablen nur die
Ursprungs-IP-Adressen enthalten (also ein klares &ldquo;Verlasst Euch nicht
auf die Umgebungsvariablen!&rdquo;).</p>

<h2>Netzwerken mit Docker</h2>

<p><a href="https:/www.twitter.com/aschmidt75">Andreas Schmidt</a> stellte eine
ganze Reihe von Varianten vor, mit denen man die Container im Netzwerk
auf unterschiedliche Arten und Weisen verknoten kann. Soweit ganz
interessant, aber nicht meine &ldquo;Liga&rdquo;, wo ich mich gut auskenne.</p>

<h2>Fazit</h2>

<p>Bei Docker in Bezug auf Orchestrierung und Container-Linken gibt es
recht viel Bewegung und fÃ¼r mich kristallisieren sich die
Ã¼berzeugenden Konzepte noch nicht so richtig heraus, um damit in eine
Produktivumgebung zu gehen. Im Bereich der Entwicklung und der Tests
nutze ich die Container von Docker schon recht gerne, bei
Produktiv-Umgebungen schreckt mich die Vielzahl an Werkzeugen und zum
Teil auch die KomplexitÃ¤t doch noch etwas.</p>

<p>Jedenfalls wieder ein gutes Meetup mit Ideen und Anregungen. Ich finde
das schon sehr auÃergewÃ¶hnlich (besonders wenn man es mit anderen
Branchen vergleicht), dass sich Leute zum Austauschen Ã¼ber Technologie
treffen, VortrÃ¤ge vorbereiten etc.</p>

<h2>Links zu den Folien</h2>

<ul>
<li><a href="https://speakerdeck.com/rossbachp/docker-meetup-frankfurt-2015-docker-orchestration">Peter Rossbach, Docker Orchestation</a></li>
<li><a href="https://speakerdeck.com/aschmidt75/docker-networking">Andreas Schmidt, Docker Networking</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[EindrÃ¼cke vom 31C3]]></title>
    <link href="http://www.dbrunner.de/blog/2015/01/05/eindrucke-vom-31c3/"/>
    <updated>2015-01-05T17:03:00+00:00</updated>
    <id>http://www.dbrunner.de/blog/2015/01/05/eindrucke-vom-31c3</id>
    <content type="html"><![CDATA[<p>Dieses Jahr habe ich mich einmal aufgerafft und bin das erste mal zum
Congress des CCC nach Hamburg gefahren. Im Folgenden ein paar
EindrÃ¼cke:</p>

<h2>Drumherum</h2>

<p>Ich fand den <a href="http://events.ccc.de/congress/2014/wiki/Main_Page">31C3</a> ein tolles Ereignis: Sehr professionell und
umsichtig organisiert. Ãberall, wo ich hinkam, war man nett und
freundlich, insgesamt eine sehr willkommende AtmosphÃ¤re. Nur der
Termin, der ist ja doch etwas sperrig.</p>

<h2>VortrÃ¤ge</h2>

<p>Ich konnte einige VortrÃ¤ge anhÃ¶ren, von denen haben mir die folgenden
besonders gut gefallen (ich habe mal die Links zu den Videos und die Links zu den EintrÃ¤gen im Fahrplan aufgefÃ¼hrt, oft gibt es im Fahrplan auch noch zugehÃ¶riges Material und weitere Hinweise):</p>

<ul>
<li><p><a href="http://media.ccc.de/browse/congress/2014/31c3_-_6264_-_de_-_saal_1_-_201412271245_-_wir_beteiligen_uns_aktiv_an_den_diskussionen_-_martin_haase_maha.html">&ldquo;Wir beteiligen uns aktiv an den Dikussionen&rdquo;</a> <a href="http://events.ccc.de/congress/2014/Fahrplan/events/6264.html">(Link im Fahrplan)</a> von Martin Haase, der die <a href="http://www.digitale-agenda.de/">Digitale Agenda</a> der Bundesregierung aus sprachwissenschaftlicher Sicht entlarvt als das, was es ist: HeiÃe Luft und wenig Konkretes, schon gar nicht fÃ¼r den &ldquo;BÃ¼rger&rdquo;. Besonders spannend fand ich den Teil des &ldquo;PDF befreien&rdquo;, denn die Bundesregierung hat nur ein wenig konsistentes PDF bereit gestellt, dass maha erst einmal in einen Text umwandeln musste, mit dem er mit seinen Werkzeugen arbeiten konnte. In der Diskussion wurde er dazu auch noch einmal befragt und meinte, Markdown, das sei eigentlich ein ganz gutes Format.</p></li>
<li><p>Die beiden SS7-VortrÃ¤ge von <a href="http://media.ccc.de/browse/congress/2014/31c3_-_6249_-_en_-_saal_1_-_201412271715_-_ss7_locate_track_manipulate_-_tobias_engel.html">Tobias Engel</a> <a href="http://events.ccc.de/congress/2014/Fahrplan/events/6249.html">(Fahrplan)</a> und <a href="http://media.ccc.de/browse/congress/2014/31c3_-_6122_-_en_-_saal_1_-_201412271830_-_mobile_self-defense_-_karsten_nohl.html">Karsten Nohl</a> <a href="http://events.ccc.de/congress/2014/Fahrplan/events/6122.html">(Fahrplan)</a>: Die Talks fand ich incl. der Live-VorfÃ¼hrungen sehr eindrÃ¼cklich und haben mir vor Augen gefÃ¼hrt, dass es mit der Sicherheit im Mobilfunk noch schlechter aussieht, als ich so befÃ¼rchtet habe.</p></li>
<li><p><a href="http://media.ccc.de/browse/congress/2014/31c3_-_6369_-_en_-_saal_1_-_201412272145_-_ecchacks_-_djb_-_tanja_lange.html">ECCHacks</a> <a href="http://events.ccc.de/congress/2014/Fahrplan/events/6369.html">(Fahrplan)</a> von djb und Tanja Lange: Ein Bekannter empfahl mir den Vortrag und meinte, ich kÃ¶nnte da schon was verstehen, obwohl ich mich mit diesen Ellpitischen Kurven nicht wirklich auskenne. Der Talk war didaktisch sehr gut aufbereitet und ich habe trotz der spÃ¤ten Stunde ein bisschen verstanden (glaube ich), worum es da eigentlich geht.</p></li>
<li><p><a href="http://media.ccc.de/browse/congress/2014/31c3_-_6294_-_de_-_saal_1_-_201412281815_-_vor_windows_8_wird_gewarnt_-_ruedi.html">Vor Windows 8 wird gewarnt</a> <a href="http://events.ccc.de/congress/2014/Fahrplan/events/6294.html">(Fahrplan)</a> von ruedi: Ein kurzweiliger Vortrag Ã¼ber &ldquo;Secure Boot&rdquo; und andere Schwierigkeiten mit &ldquo;Windows 8&rdquo;.</p></li>
<li><p><a href="http://media.ccc.de/browse/congress/2014/31c3_-_6258_-_en_-_saal_1_-_201412282030_-_reconstructing_narratives_-_jacob_-_laura_poitras.html">Reconstructing naraatives</a> <a href="http://events.ccc.de/congress/2014/Fahrplan/events/6258.html">(Fahrplan)</a> von Jacob Appelbaum und Laura Poitras: Das war im voll besetzten Saal 1 ein sehr eindrÃ¼cklicher Vortrag, der mit Standing Ovations endete.</p></li>
<li><p><a href="http://media.ccc.de/browse/congress/2014/31c3_-_6121_-_en_-_saal_2_-_201412291715_-_what_ever_happened_to_nuclear_weapons_-_michael_buker.html">What Ever Happened to Nuclear Weapons?</a> <a href="http://events.ccc.de/congress/2014/Fahrplan/events/6121.html">(Fahrplan)</a> von Michael BÃ¼ker: Diesen Vortrag fand ich vom Aufbau und der Didaktik sehr gut vorbereitet. Als wichtige Erkenntnis habe ich fÃ¼r mich den <a href="http://de.wikipedia.org/wiki/Kernwaffenteststopp-Vertrag">Kernwaffenstopp-Vertrag (englisch Comprehensive Nuclear-Test-Ban Treaty)</a> mitgenommen, einen internationalen Vertrag, der sÃ¤mtliche Kernwaffentests verbietet, der aber noch nicht in Kraft getreten ist; dieser Vertrag geht weiter als der Nuclear Test Ban Treaty aus den 1960er Jahren, der Kernwaffenversuche in der AtmosphÃ¤re, im Weltraum und unter Wasser verbietet. Dennoch gibt es hierzu schon eine <a href="http://www.ctbto.org/">Organisation, die Preparatory Commission for the Comprehensive Nuclear-Test-Ban Treaty Organisation</a>, der man auch auf Twitter <a href="http://twitter.com/ctbto_alerts">folgen kann</a>. Diese  &ldquo;Preparatory Commission&rdquo; bereitet das Inkraftreten vor und baut ein Ãberwachungssystem auf.</p></li>
<li><p><a href="http://media.ccc.de/browse/congress/2014/31c3_-_6128_-_en_-_saal_1_-_201412291830_-_thunderstrike_efi_bootkits_for_apple_macbooks_-_trammell_hudson.html">EFI bootkits for Apple MacBooks</a> <a href="http://events.ccc.de/congress/2014/Fahrplan/events/6128.html">(Fahrplan)</a> von Trammell Hudson: Ich fand das sehr spannend vorgetragen (incl. Hexdumps etc.), wie Trammel Hudson durch &ldquo;Reverse Engineering&rdquo; auf ein Sicherheitsproblem bei Apple-Produktion gestoÃen ist und dieses dann in einem Proof-of-Concept auch ausnutzen konnte.</p></li>
</ul>


<p>Aufgrund des riesigen Angebots an VortrÃ¤gen, Workshops etc. muss ich
mir in den kommenden Tagen glaube ich noch den einen oder anderen
Vortrag als Video ansehen.</p>

<h2>MorgenGrauen-Stammtisch</h2>

<p>Etwas spontan und nicht so sonderlich koordiniert haben wir auch einen
<a href="http://mg.mud.de">MorgenGrauen</a>-Stammtisch ausgerufen und siehe da: Drei Spieler und zwei
GÃ¤ste fanden sich ein, so dass man bei einem Bier ein wenig plaudern
und sich austauschen konnte.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Aus zwei mach eins]]></title>
    <link href="http://www.dbrunner.de/blog/2015/01/04/aus-zwei-mach-eins/"/>
    <updated>2015-01-04T16:16:08+00:00</updated>
    <id>http://www.dbrunner.de/blog/2015/01/04/aus-zwei-mach-eins</id>
    <content type="html"><![CDATA[<p>Bisher hatte ich meine Blog-EintrÃ¤ge auf zwei Blogs aufgeteilt,
<a href="http://blog.krrrcks.net">eines</a> mit mehr technischen (und zum Teil
englischen Texten) und dieses hier mit deutschen Texten. Ich denke,
ich werde das auf dieses eine Blog hier konzentrieren. Das reduziert
doch etwas den Verwaltungsaufwand. Ich habe die Texte vom nun etwas
still gelegten Blog hier herÃ¼ber kopiert.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Ich habe mal Octopress aktualisert]]></title>
    <link href="http://www.dbrunner.de/blog/2014/12/21/ich-habe-mal-octopress-aktualisert/"/>
    <updated>2014-12-21T11:58:16+00:00</updated>
    <id>http://www.dbrunner.de/blog/2014/12/21/ich-habe-mal-octopress-aktualisert</id>
    <content type="html"><![CDATA[<p>Neulich fiel mir auf, dass die Suchfunktion, die auf Google basiert,
nicht nur auf der eigenen Homepage, sondern im &ldquo;gesamten&rdquo; Suchindex
von Google gesucht hat. Eben flatterte dieser
<a href="https://twitter.com/octopress/status/546528904115404800">Tweet</a> mit
<a href="https://github.com/imathis/octopress/commit/514ed5eb9f6bb91a6f3288febf3c2ba892a9b693">Link</a>
zu einem Fix an mir vorbei und da hat sich wohl die API geÃ¤ndert.</p>

<p><img src="http://www.dbrunner.de/img/2014-12-21-octopress.png" alt="Octopress-Tweet" /></p>

<p>Also habe ich mich einmal an den
<a href="http://octopress.org/docs/updating/">Hinweisen</a> zum Aktualisieren von
Octopress orientiert. Hierzu werden die folgenden Schritte vorgeschlagen:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>git pull octopress master      # Get the latest Octopress
</span><span class='line'>bundle install                 # Keep gems updated
</span><span class='line'>rake update_source             # update the template's source
</span><span class='line'>rake update_style              # update the template's style</span></code></pre></td></tr></table></div></figure>


<p>Soweit lief das auch. Es tauchten anschlieÃend zwei Probleme auf:</p>

<ol>
<li><p>Das <code>execjs</code> jammerte, dass ihm irgendwie eine
JavaScript-Bibliothek fehlte. Nach kurzer Recherche gab es die
Empfehlung, die Zeile <code>gem 'therubyracer'</code> in das <code>Gemfile</code>
aufzunehmen. Okay, das funktionierte schon einmal.</p></li>
<li><p>Bei den Feeds fÃ¼r die Kategorien jammerte das Octopress ein
ungÃ¼ltiges Layout an. In <code>category_feed.xml</code> stand in der Tat
<code>layout: nil</code>. Ich habe das auf <code>layout: page</code> geÃ¤ndert. Nun tat
auch dies.</p></li>
</ol>


<p>Mit dem Update funktioniert nun auch das Such-Formular wieder.</p>

<p><strong>ErgÃ¤nzung:</strong> Ich lasse das Jekyll und Octopress in einem
   <a href="http://www.dbrunner.de/blog/2014/06/10/relaunch-fast-fertig/">Docker-Container</a> laufen und irgendwie bekam ich bei <code>rake preview</code>
   meine Seite nicht mehr zu sehen. Da ich mich mit Ruby und den
   Komponenten nicht so gut auskenne, weiÃ ich nicht, ob mein &ldquo;Fix&rdquo; so
   gut ist: Ich habe im <code>Rakefile</code> den <code>rackup</code>-Aufruf um den
   Parameter <code>-o 0.0.0.0</code> ergÃ¤nzt. Dann bekam ich vom Host wieder eine
   Verbindung zum Webserver im Octopress-Container.</p>

<p><strong>Update vom 04. Januar 2014:</strong> Nach einem kurzen
  <a href="https://twitter.com/Krrrcks/status/546667456128114688">GesprÃ¤ch</a>
  via Twitter habe ich mich entschieden, den eingebauten Server doch
  wieder so zu belassen, wie es im <code>Rakefile</code> ursprÃ¼nglich
  stand. Statt dessen habe ich einfach in dem Docker-Container einen
  <code>nginx</code> hinzuinstalliert, der dann mein <code>public</code>-Verzeichnis an den
  Port 4000 ausliefert. So funktioniert es wieder prima: Ich starte
  den <code>nginx</code> und lasse dann das <code>rake watch</code> laufen, um die Seiten
  immer wieder neu zu erzeugen, wenn sich Dinge geÃ¤ndert haben.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA["Neues" Arbeitspapier]]></title>
    <link href="http://www.dbrunner.de/blog/2014/12/18/neues-arbeitspapier/"/>
    <updated>2014-12-18T18:24:27+00:00</updated>
    <id>http://www.dbrunner.de/blog/2014/12/18/neues-arbeitspapier</id>
    <content type="html"><![CDATA[<p>Zusammen mit
<a href="http://www.bk.tudelft.nl/en/about-faculty/departments/otb/about-otb/staff/alle-medewerkers/haffner-marietta/">Marietta Haffner</a>
hatte ich fÃ¼r die
<a href="http://www.ccnorway.no/enhr2012/">ENHR-Konferenz im Jahr 2012 in Lillehammer</a>
ein Konferenzpapier vorbereitet, das Marietta dort vorgestellt
hatte. Wir haben nun in der Arbeitspapier-Reihe des OTB an der TU
Delft eine Ã¼berarbeitete Fassung <a href="http://www.bk.tudelft.nl/fileadmin/Faculteit/BK/Over_de_faculteit/Afdelingen/OTB/publicaties/Working_papers/OTB_Working_papers_2014-07_German_cooperatives.pdf">eingestellt</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Aus der Entscheidung des BVerfG zur Erbschaftsteuer]]></title>
    <link href="http://www.dbrunner.de/blog/2014/12/18/aus-der-entscheidung-des-bverfg-zur-erbschaftsteuer/"/>
    <updated>2014-12-18T07:41:37+00:00</updated>
    <id>http://www.dbrunner.de/blog/2014/12/18/aus-der-entscheidung-des-bverfg-zur-erbschaftsteuer</id>
    <content type="html"><![CDATA[<p>Das Bundesverfassungsgerichts hat in seiner <a href="http://www.bundesverfassungsgericht.de/SharedDocs/Entscheidungen/DE/2014/12/ls20141217_1bvl002112.html">Entscheidung</a>
vom 17. Dezember 2014 (1 BvL 21/12) Regelungen zur Erbschaftsteuer als
verfassungwidrig moniert. Ich finde in der Entscheidung eigentlich den
fÃ¼nften Leitsatz mit am interessantesten:</p>

<blockquote><p>&ldquo;Ein Steuergesetz ist verfassungswidrig, wenn es Gestaltungen zulÃ¤sst,
mit denen Steuerentlastungen erzielt werden kÃ¶nnen, die es nicht
bezweckt und die gleichheitsrechtlich nicht zu rechtfertigen sind.&rdquo;</p></blockquote>

<p>Nun bin ich kein Steuer-, Verfassungsrechtsspezialist (genaugenommen
gar kein Rechtsspezialist) und weiÃ nicht, ob dieser Satz nicht
ohnehin schon gilt oder Verfassungs- und SteurrechtsrealitÃ¤t ist. Ich
habe es allerdings in dieser Klarheit noch nicht gelesen. Und wenn ich
mir so das eine oder andere Steuergesetz und seine Wirkungen ansehe,
dann kommt da unter diesem Leitsatz vielleicht in den kommenden Jahren
einiges auf die Gerichte zu.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Migration alter Blog-EintrÃ¤ge]]></title>
    <link href="http://www.dbrunner.de/blog/2014/12/17/migration/"/>
    <updated>2014-12-17T18:11:00+00:00</updated>
    <id>http://www.dbrunner.de/blog/2014/12/17/migration</id>
    <content type="html"><![CDATA[<p>Es kamen lange Winterabende und ich habe die alten Blog-EintrÃ¤ge von
der mittels Org-Mode erstellten Seite hier nach Octopress
migriert. Im Archiv sind diese zu finden und die Links etc. sollten
nun auch passend mit migriert worden sein.</p>

<p>Bei der Konvertierung habe ich ein Programm kennengelernt, das mir
sehr geholfen hat: <a href="http://johnmacfarlane.net/pandoc/">Pandoc</a>. Das
ist ein Konverter, der Text- und Markupdateien hin und her
konvertieren kann. Dabei beherrscht er eine ganze Reihe von
Formaten. Insbesondere kann er das Org-Mode-Format (das ich fÃ¼r viele
Dinge verwende) ebenso wie LaTeX und Markdown (daneben aber auch noch
eine Legion von Formaten).</p>

<p>Da mein Hauptdateiformat ohnehin &ldquo;Textdateien&rdquo; sind (&ldquo;Never trust a
file that isn&rsquo;t ASCII&rdquo;) ist das sehr praktisch, um zwischen
verschiedenen Markup-Formaten hin und her zu springen.</p>

<p>FÃ¼r die Migration meine Blog-EintrÃ¤ge lief dies wie folgt: Ich hatte
die in der alten Homepage mit Org-Mode und Org-Jekyll erstellt. Dabei
hatte das Org-Jekyll-Modul entsprechende HTML-Dateien mit einem
YAML-Header erzeugt. Mittels Pandoc konnte ich die nun wieder nach
Markdown konvertieren, habe die YAML-Header ein wenig angepasst,
Kategorien aktualisiert und noch mal das Markup zwecks ZeilenumbrÃ¼che,
FuÃnoten und Links geprÃ¼ft und leicht angepasst. Insgesamt sehr
schnell bewÃ¤ltigbar.</p>

<p>Dieser ganze Zoo rund um Markdown und andere Ã¤hnliche Formate ist zwar
manchmal ein bisschen unÃ¼bersichtlich, aber mir gefÃ¤llt das sehr gut,
dass man mit wenig Markup schÃ¶n Textdateien strukturieren kann und
dann mit Pandoc auch gut hin und her konvertieren kann.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Wie das Haus von Bundesministerin Nahles mauert]]></title>
    <link href="http://www.dbrunner.de/blog/2014/11/21/wie-das-haus-von-bundesministerin-nahles-mauert/"/>
    <updated>2014-11-21T10:39:08+00:00</updated>
    <id>http://www.dbrunner.de/blog/2014/11/21/wie-das-haus-von-bundesministerin-nahles-mauert</id>
    <content type="html"><![CDATA[<p>Ein Gesetzesvorhaben der groÃen Koalition ist eine Regelung zur
Tarifeinheit. Passend in die Tarifauseinandersetzungen bei der
Deutschen Bahn zeigte Bundesministerin Nahles Entschlossenheit und
Tatkraft:</p>

<p>Am 28. Oktober 2014
<a href="http://www.bmas.de/DE/Themen/Arbeitsrecht/Meldungen/gesetzentwurf-tarifeinheit.html;jsessionid=FB47DA2A8F96F14200ECE524ACBD96BC">informierte sie</a>
die Presse Ã¼ber den Gesetzentwurf ihres Hauses zur
Tarifeinheit. Dieser solle in die Ressortabstimmung gehen und
am 3. Dezember im Kabinett verabschieden werden. Den Abschluss des
parlamentarischen Verfahrens erwartete Frau Nahles fÃ¼r den Sommer
2015.</p>

<p>Ãber die Vorstellung und den Inhalt des Entwurfs berichtete
ausfÃ¼hrlich in zwei Berichten die FAZ
(<a href="http://www.faz.net/-i2k-7vmd0">hier</a> und
<a href="http://www.faz.net/-gqg-7vng9">hier</a>). Den Berichten nach fand ein
GesprÃ¤ch der FAZ mit der Bundesministerin statt. Der FAZ lag der
Referentenentwurf vor. Den Berichten ebenfalls zu entnehmen war, dass
sozialpolitische und arbeitsrechtliche InteressenverbÃ¤nde wie die
Bundesvereinigung der Arbeitgeber und auch der Deutsche
Gewerkschaftsbund Ã¼ber den Entwurf verfÃ¼gten, diese genannten sogar an
&ldquo;der Ausarbeitung des Gesetzes beteiligt&rdquo; waren (Zitat aus dem
FAZ-Bericht).</p>

<p>Ich bin ja skeptisch, wie man das, was die Koalition sich da
vorgenommen hat, regeln kann. Also dachte ich mir: Wenn die Zeitung
davon weiÃ, die InteressenverbÃ¤nde mitgearbeitet haben und auch denen
der Entwurf vorlag und dann die Bundesministerin auch noch hierÃ¼ber
PressegesprÃ¤che fÃ¼hrt und den Entwurf Ã¶ffentlich &ldquo;vorstellt&rdquo;, dann
kann ich da ja auch einmal einen Blick hineinwerfen. Ich habe, da
ich den Entwurf nicht auf der Homepage entdeckte, diesen beim
Bundesministerium fÃ¼r Arbeit und Soziales angefordert.</p>

<p>So einfach geht es aber nicht: Es antwortete mir am <em>29. Oktober 2014</em>
das &ldquo;Kommunikationscenter&rdquo; des Bundesministeriums fÃ¼r Arbeit und
Soziales wie folgt:</p>

<blockquote><p>Sollten Sie (&hellip;) den Gesetzentwurf zur Tarifeinheit meinen, so
mÃ¼ssen wir Ihnen mitteilen, dass dieser noch nicht verÃ¶ffentlicht
wurde. Er geht in KÃ¼rze in die Ressortabstimmung und kann erst
danach verÃ¶ffentlicht werden.</p></blockquote>

<p>Ich wies in einer Antwort darauf hin, dass das ja nicht so ganz sein
kÃ¶nnte, dass die Tarifparteien, interessierte VerbÃ¤nde und die Presse
den Entwurf vorliegen hÃ¤tten, der gemeine BÃ¼rger sich aber mit der
PresseerklÃ¤rung der Bundesministerin (ein MP3-File mit 2:36 Minuten
LÃ¤nge) bescheiden mÃ¼sse. Am <em>30. Oktober 2014</em> teilte das
Kommunikationscenter mit, dass sie die Anfrage an die Fachabteilung
weitergeben wollten, dafÃ¼r aber noch meine Postanschrift
benÃ¶tigten. Diese habe ich umgehend Ã¼bermittelt. Es passierte erst
einmal nichts. Am <em>4. November 2014</em> wollte ich dann den Stand wissen
(es kann ja nicht so schwer sein, ein PDF per E-Mail zu versenden) und
auÃerdem, welche Fachabteilung dafÃ¼r zustÃ¤ndig ist (dann kann man das
ja schnell per Telefon oder E-Mail klÃ¤ren). Nichts
passierte. Am <em>7. November 2014</em> habe ich dann noch mal erklÃ¤rt, dass
ich den Entwurf wirklich mÃ¶chte und die Anfrage formal auf das
Informationsfreiheitsgesetz gestÃ¼tzt. Nun wachte das
Kommunikationscenter am <em>10. November 2014</em> auf und teilte mit, dass sie
die Anfrage an die zustÃ¤ndige Fachabteilung weitergeleitet
hÃ¤tten. Welche das ist, mochte man mir aber immer noch nicht
mitteilen.</p>

<p>Das war es dann wieder, das Bundesministerium verfiel erneut in
Stille. Seit dem sind zwei Wochen vergangen.</p>

<p>Da mich der Entwurf wirklich interessierte, habe ich einmal einen
Interessenverband angeschrieben und nach ca. einer Stunde erhielt ich den Entwurf.</p>

<p>Ich stelle mir da ja schon einige Fragen: Was ist eigentlich so
schwer daran, einen Referentenentwurf, den man ohnehin breit hat
zirkulieren lassen, einem BÃ¼rger zur VerfÃ¼gung zu stellen? Warum
antwortet die Fachabteilung Ã¼ber einen Zeitraum vom 4. November 2014
bis heute einfach gar nicht?</p>

<p>Mir drÃ¤ngt sich jedenfalls der Eindruck auf, dass das Ministerium von
Frau Nahles die Diskussion gestalten mÃ¶chte. Dabei soll wohl die
Bundesministerin als zupackende und problemlÃ¶sende Politikerin
dargestellt werden. Hierzu werden VerbÃ¤nde und Medien exklusiv mit
Details versorgt.  Der gemeine BÃ¼rger soll sich davon beeindrucken
lassen und bloÃ nicht nach Details fragen; die erfÃ¤hrt er dann schon,
wenn die Politik und Ministerialverwaltung es fÃ¼r geboten halten.</p>

<p>P.S.: Ich weiÃ, dass ReferentenentwÃ¼rfe normalerweise nicht auf der
Homepage erscheinen und Gesetzesvorhaben vorab mit VerbÃ¤nden
diskutiert werden. Ich halte das auch grundsÃ¤tzlich fÃ¼r sinnvoll. Ich
habe aber bisher noch nicht ein solches &ldquo;Mauern&rdquo; erlebt. Bisher
erhielt ich dort, wo ich angefragt hatte, immer ohne Schwierigkeiten
Auskunft.</p>

<p><strong>Update (01. Dezember 2014):</strong> Zwischenzeitlich habe ich den
  Referentenentwurf fÃ¼r jedermann zum Download bei der taz gefunden:
  <a href="http://taz.de/static/pdf/ReferentenentwurfTarifeinheit.pdf">PDF</a></p>

<p><strong>Update (13. Dezember 2014):</strong> Am 11. Dezember 2014 hat das
  Bundeskabinett den Gesetzentwurf zur Tarifeinheit
  <a href="http://www.bundesregierung.de/Content/DE/Kabinettssitzung/2014/12/2014-12-11-kabinett.html?nn=434518">beschlossen</a>,
  er findet sich nun
  <a href="http://www.bmas.de/DE/Service/Presse/Pressemitteilungen/Tarifeinheit-staerkt-sozialpartnerschaft.html?nn=31846">auf der</a>
  Homepage des Bundesministeriums fÃ¼r
  Arbeit und Soziales:
  <a href="http://www.bmas.de/SharedDocs/Downloads/DE/Thema-Arbeitsrecht/entwurf-gesetz-tarifeinheit.pdf?__blob=publicationFile">PDF</a>
  Wenig erstaunlicherweise habe ich auf meine Anfrage vom 29. Oktober
  2014 auÃer den oben dargestellten Nachrichten des
  &ldquo;Kommunikationscenters&rdquo; nichts gehÃ¶rt.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Warten auf den technischen Fortschritt als politisches Prinzip?]]></title>
    <link href="http://www.dbrunner.de/blog/2014/11/13/warten-auf-den-technischen-fortschritt-als-politisches-prinzip/"/>
    <updated>2014-11-13T09:53:28+00:00</updated>
    <id>http://www.dbrunner.de/blog/2014/11/13/warten-auf-den-technischen-fortschritt-als-politisches-prinzip</id>
    <content type="html"><![CDATA[<p>Am 12. November 2014 sendete der
<a href="http://www.deutschlandfunk.de">Deutschlandfunk</a> in der Reihe
&ldquo;Hintergrund&rdquo; einen
<a href="http://www.deutschlandfunk.de/energetische-sanierung-widerstand-gegen-das-daemmen-waechst.724.de.html?dram:article_id=303005">Bericht</a>
Ã¼ber die energetische Sanierung mit WÃ¤rmedÃ¤mmverbundsystemen.</p>

<p>Zu der Diskussion wollte sich die zustÃ¤ndige Bundesministerin Barbara
Hendricks nicht Ã¤uÃern, das Thema sei nur ein Randthema und sie habe
andere PrioritÃ¤ten. Sehr interessant waren dafÃ¼r dann die Meinungen des
sie vertretenden StaatssekretÃ¤rs <a href="http://www.bmub.bund.de/bmub/leitung-des-hauses/lebenslauf-von-herrn-gunther-adler/">Gunther Adler</a>.</p>

<p>In diesem Blogpost will ich auf einen Aspekt des Berichts eingehen. Es
sei wohl so, dass die Entsorgung von WÃ¤rmedÃ¤mmverbundsystemen (also im
Wesentlichen auf verschiedene Arten behandeltes Polystyrol) schwierig
ist. So wird gesagt:</p>

<blockquote><p>&ldquo;Das groÃe Problem ist gerade bei der Polystyrol-DÃ¤mmung, dass die
Lebenserwartung der DÃ¤mmplatten relativ gering ist. Man geht davon
aus, dass sie 20 oder 30 Jahre an der Fassade bleiben kÃ¶nnen, dann
ersetzt werden mÃ¼ssen.&rdquo;</p></blockquote>

<p>Ãber die Entsorgung wurde gesagt:</p>

<blockquote><p>&ldquo;Das DÃ¤mmmaterial Polystyrol darf nicht auf die MÃ¼lldeponie, unter
anderem wegen der erwÃ¤hnten Flammschutzmittel. Das Material soll in
MÃ¼llverbrennungsanlagen vernichtet werden, &hellip;&rdquo;</p></blockquote>

<p>Auf diese Thematik angesprochen, entgegnete der StaatssekretÃ¤r unter
anderem:</p>

<blockquote><p>&ldquo;&hellip; da gibt es berechtigte Fragen, da gibt es auch nichts unter den
Tisch zu kehren. Da gibt es im Moment noch Forschungsbedarf.&rdquo;</p></blockquote>

<p>Die DLF-Redakteure wiesen hier jedoch darauf hin, dass das Material
seit Langem eingesetzt wÃ¼rde. In den vergangenen 35 Jahren seien 900
Millionen Quadratmeter WÃ¤rmedÃ¤mmverbundsysteme verbaut worden, davon
80 Prozent mit Polystyrol. Hierauf der StaatssekretÃ¤r:</p>

<blockquote><p>&ldquo;Wenn wir da schon heute die Forschung anlaufen lassen und fragen,
was passiert eigentlich in 30 oder 40 oder 50 Jahren, wenn das dann
mal in die MÃ¼llverbrennungsanlage geht, da sollten wir doch offen
fÃ¼r technischen Fortschritt in Deutschland sein, dass es unserer
Industrie und unserer Forschung gelingen wird, beispielsweise
Filteranlagen zu entwickeln, die wirklich garantieren, dass hundert
Prozent aller Schadstoffe abgefangen werden.&rdquo;</p></blockquote>

<p>Ich fasse zusammen: Das Bundesministerium fÃ¼r Umwelt, Naturschutz, Bau
und Reaktorsicherheit unterstÃ¼tzt offen das Inverkehrbringen von
Stoffen, deren Entsorgung zumindest &ldquo;offene Fragen&rdquo; und
&ldquo;Forschungsbedarf&rdquo; bringt und das Ministerium findet, der technische
Fortschritt wird es schon richten. Kurzum, es gilt das Prinzip
&ldquo;Hoffnung auf die Zukunft&rdquo; und die Last, sich die Entsorgung zu
Ã¼berlegen, bÃ¼rdet man den nachfolgenden Generationen auf.</p>

<p>Wo sind in diesem Zusammenhang eigentlich die ganzen Papiere und
politischen AnsÃ¤tze zu Nachhaltigkeit, Verantwortung, Schutz
zukÃ¼nftiger Generationen geblieben? Im Ãbrigen widerspricht die
Haltung auch dem vom Bauministerium selbst herausgegebenen
<a href="http://www.nachhaltigesbauen.de/leitfaeden-und-arbeitshilfen-veroeffentlichungen/leitfaden-nachhaltiges-bauen-2013.html">Leitfaden Nachhaltiges Bauen 2013</a>,
in dem besonderer Wert auf den Lebenszyklus von GebÃ¤uden auch unter
dem Gesichtspunkt der Entsorgung von Materialen gelegt wird.</p>

<p>Wenn schon das Thema &ldquo;WÃ¤rmedÃ¤mmverbundsysteme&rdquo; nicht die PrioritÃ¤t der
Bundesministerin hat, so muss sie sich fragen lassen, ob gerade im
Umwelt- und Bauressort das Prinzip &ldquo;Hoffnung auf die Zukunft&rdquo;
Leitlinie ihrer Politik ist.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[AktenfÃ¼hrung beim Beitragsservice]]></title>
    <link href="http://www.dbrunner.de/blog/2014/10/05/aktenfuhrung-beim-beitragsservice/"/>
    <updated>2014-10-05T10:45:13+00:00</updated>
    <id>http://www.dbrunner.de/blog/2014/10/05/aktenfuhrung-beim-beitragsservice</id>
    <content type="html"><![CDATA[<p>Im Jahr 2012 habe ich mich rechtmÃ¤Ãig (was allerdings auch etwas
Ãberzeugungsarbeit kostete) von der damaligen GEZ abgemeldet und die
neue Beitragsnummer mitgeteilt, Ã¼ber die meine damalige RundfunkgebÃ¼hr
verbucht werden sollte. Der GEZ war meine alte Beitragsnummer, die
neue Beitragsnummer sowie meine Anschrift bekannt. Soweit so gut,
besondere VerÃ¤nderungen sind in der Zwischenzeit nicht eingetreten.</p>

<p>Am <strong>17. April 2014</strong> erreicht mich ein Schreiben des
Beitragsservices. Sie schreiben dort:</p>

<blockquote><p>Auf Basis gesetzlicher Bestimmungen haben wir die Adressdaten der
EinwohnermeldeÃ¤mter mit den bei uns angemeldeten Beitragszahlern
abgeglichen. Unter Ihrem Namen konnten wir fÃ¼r diese Wohnung kein
Beitragskonto finden.</p></blockquote>

<p>Oh! Das ist interessant: Sie kannten meinen Namen und Anschrift,
schafften es aber dennoch nicht, das mit dem damaligen Vorgang
zusammenzubringen? Recht schwaches Bild fÃ¼r so eine Institution, die
doch so professionell mit Adressdaten umzugehen weiÃ.</p>

<p>Ich beschloss, den Beitragsservice etwas zappeln zu lassen. Meine
Antwort vom <strong>24. April 2014</strong> war daher entsprechend kryptisch:</p>

<blockquote><p>Ich verweise auf mein Schreiben vom 24. April 2012 an die
seinerzeitige GebÃ¼hreneinzugszentrale, die Antwort hierauf vom
10. Mai 2012 und mein Schreiben vom 16. Mai 2012 mit dem
Aktenzeichen (&hellip;). Am seinerzeitigen Sacheverhalt hat sich nichts
geÃ¤ndert. DemgemÃ¤Ã wird ein Rundfunkbeitrag fÃ¼r die von mir bewohnte
Wohnung entrichtet und der Rundfunkbeitrag wird auch regelmÃ¤Ãig
abgebucht.</p></blockquote>

<p>Nun war ich gespannt, ob sie es mit etwas MÃ¼he nicht doch hinbekommen,
den Vorgang von damals wieder zu finden und ihren aktuellen Vorgang
abzuschlieÃen. Nach der Beitragsservice-Bedenkzeit von acht Wochen
(ich meine mich zu erinnern, dass die GEZ es meistens in sechs Wochen
geschafft hatte, eine Antwort zu schreiben), kam nun mit Schreiben vom
<strong>26. Juni 2014</strong> eine erneute Bitte um Mitteilung der Beitragsnummer:</p>

<blockquote><p>Gerne bearbeiten wir Ihre Angaben. HierfÃ¼r benÃ¶tigen wir jedoch noch
die Beitragsnummer, unter der die Wohnung angemeldet ist. Teilen Sie
uns diese bitte auf dem Antwortbogen mit.</p></blockquote>

<p>Alternativ kÃ¶nnen sie das wohl auch aus der Bankverbindung, frÃ¼heren
Anschriften, frÃ¼heren Namen etc. herausfinden. Warum jedoch nicht Ã¼ber
meine Anschrift und mein damaliges Schreiben? Ach ja, die Ã¼blichen
Daumenschrauben wurden dem Schreiben noch hinzugefÃ¼gt:</p>

<blockquote><p>Sollten Sie uns nicht innerhalb der Frist (von vier Wochen, D.B.)
gehen wir davon aus, dass eine Anmeldung fÃ¼r diese Wohnung
erforderlich ist.</p></blockquote>

<p>Ahja, der Beitragsservice braucht acht Wochen um nach der
Beitragsnummer zu fragen, ich soll aber in vier Wochen antworten?</p>

<p>Nun ging mit das Porto zu sehr ins Geld und ich wechselte auf
E-Mails. Am <strong>7. Juli 2014</strong> teilte ich dem Beitragsservice noch mal alles
mit: Neue Wohnung, neue Beitragsnummer etc. Und dass Sie das ja alles
seit dem Jahr 2012 schon wÃ¼ssten. Ich ermunterte den Beitragsservice,
doch einfach noch mal einen Adressabgleich durchzufÃ¼hren:</p>

<blockquote><p>Ich bin daher etwas verwundert, dass ich nun schon wieder Ã¼ber einen bei
Ihnen bekannten und aktenkundigen Sachverhalt erneut Auskunft erteilen
soll. Denn die seinerzeit mitgeteilten Daten mussten doch irgendwie mir
und meiner Anschrift (die sich ja auch nicht geÃ¤ndert hat) zugeordnet
worden sein.
Ich bin zuversichtlich, es ist Ihnen ein Leichtes, aufgrund obiger
Informationen und Ihnen bereits vor zwei Jahren mitgeteilten
Sachverhaltes Ihren Vorgang abschlieÃen zu kÃ¶nnen.</p></blockquote>

<p>Nun ging es Schlag auf Schlag, denn vÃ¶llig unerwartet antwortete der
Beitragsservice bereits am <strong>22. Juli 2014</strong>. Und nun das erste
EingestÃ¤ndnis:</p>

<blockquote><p>Sie teilen mit, dass Sie bereits in 05.2012 mitgeteilt haben, (&hellip;)
Dieses Schreiben liegt uns leider nicht mehr vor, so dass wir auf
dessen Inhalt nicht zurÃ¼ckgreifen kÃ¶nnen.</p></blockquote>

<p>Wie kann dies sein? Es handelt sich doch um eine Verwaltung? Die
sollte doch ihre AktenfÃ¼hrung in Ordnung halten kÃ¶nnen. In meiner
E-Mail vom <strong>28. Juli 2014</strong> erlÃ¶ste ich den Beitragsservice und teilte
ihnen die Beitragsnummer mit. Allerdings nicht ohne noch ein wenig
meine Besorgnis Ã¼ber die AktenfÃ¼hrung zum Ausdruck zu bringen:</p>

<blockquote><p>Des Weiteren sehen Sie mich Ã¼berrascht, dass Sie auf ein Schreiben
aus dem Jahr 2012 keinen Zugriff mehr haben. Da ich bisher davon
ausging, dass sich die Ã¶ffentlich-rechtliche Verwaltung in
besonderem MaÃe durch die Schriftlichkeit und Aktenkundigkeit Ihres
Handelns auszeichnet, ging ich davon aus, dass zu mir auch die
Unterlagen und der Schriftverkehr verfÃ¼gbar sind. Ich bitte Sie
hÃ¶flichst mir mitzuteilen, wie dieses Schriftgut verloren gegangen
ist und wie sichergestellt ist, dass nicht alle zwei Jahre erneut
eine Anfrage wie die vom 17.04.2014 (&hellip;) bei mir eingeht.</p></blockquote>

<p>Nach vier Wochen erreichte mich dann die Auskunft am <strong>27. August
2014</strong>:</p>

<blockquote><p>Sie fragen, warum wir keinen Zugang zu Ihrem Schreiben vom
24.04.2012 hatten. Der Schriftverkehr wurde unter Ihrem abgemeldeten
Beitragskonto (&hellip;) sowie unter dem Beitragskonto (&hellip;) verfilmt. Da
Sie nun den Bezug zur Beitragsnummer (&hellip;) hergestellt haben, kÃ¶nnen
wir den Schriftverkehr einsehen. Wir hoffen, Ihnen mit diesen
ErlÃ¤uterungen weitergeholfen zu haben.</p></blockquote>

<p>Ohja, das haben sie. Nachdem der Vorgang wohl beiderseits genÃ¼gend
Schmerzen verursacht hat, habe ich es dabei bewenden lassen.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Mind the storage driver for Ubuntu cloud images (on Azure)]]></title>
    <link href="http://www.dbrunner.de/blog/2014/07/24/mind-the-storage-driver-for-ubuntu-cloud-images-on-azure/"/>
    <updated>2014-07-24T12:30:43+00:00</updated>
    <id>http://www.dbrunner.de/blog/2014/07/24/mind-the-storage-driver-for-ubuntu-cloud-images-on-azure</id>
    <content type="html"><![CDATA[<p>A few days ago I wanted to build Firefox OS&#8217; newest release for a
friend. Because I did not wanted these GB of code, binaries etc. on my
notebook I fired up an Ubuntu image on Microsoft Azure. I feared that
at a certain point in the build process I may had to download
everything to my local machine and therefore I installed Docker via a
simple</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>sudo apt-get install docker.io</span></code></pre></td></tr></table></div></figure>


<p></p>

<p>Then I started the build process as laid out on Mozilla&rsquo;s Developer
Network. But, during downloading the source code (that&rsquo;s about 12 GB
of Git repositories from Mozilla and Android), I got a &ldquo;no more space
left on device&rdquo;. That was strange: I had a 100 GB volume attached to
the VM and enough space and inodes left. After some searching I asked
on the IRC channel and got a good hint: &ldquo;What&rsquo;s your storage driver?&rdquo;</p>

<p>Well, I thought that it&rsquo;s AUFS; I wanted to add &ldquo;as usual&rdquo; because
AUFS was available on my notebook from the beginning. But a <code>docker.io
info</code> gave me:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ sudo docker.io info
</span><span class='line'>Containers: 0
</span><span class='line'>Images: 0
</span><span class='line'>Storage Driver: devicemapper
</span><span class='line'> Pool Name: docker-8:1-131188-pool
</span><span class='line'> Data file: /var/lib/docker/devicemapper/devicemapper/data
</span><span class='line'> Metadata file: /var/lib/docker/devicemapper/devicemapper/metadata
</span><span class='line'> Data Space Used: 291.5 Mb
</span><span class='line'> Data Space Total: 102400.0 Mb
</span><span class='line'> Metadata Space Used: 0.7 Mb
</span><span class='line'> Metadata Space Total: 2048.0 Mb
</span><span class='line'>Execution Driver: native-0.1
</span><span class='line'>Kernel Version: 3.13.0-29-generic
</span><span class='line'>WARNING: No swap limit support</span></code></pre></td></tr></table></div></figure>


<p>I then learned that somehow the DeviceMapper driver only allows a
certain amount of diffs and I reached that amount with my build
process. (Maybe it&rsquo;s possible to relax that restriction but I do not
know how.)</p>

<p>I learned as well that the Ubuntu cloud image that is provided by
Microsoft Azure doesn&rsquo;t have AUFS support. Therefore Docker uses the
DeviceMapper storage driver instead. After I installed the AUFS
support I could export the images, change the storage driver and
import the images again.</p>

<p>It would be nice seeing the Docker documentation being more detailed
on those storage drivers.</p>

<p><strong>(Update 2014-10-23)</strong> Thanks to
 <a href="http://blog.iron.io/2014/10/docker-in-production-what-weve-learned.html">this blog post from Iron.io</a>
 I found some documentation of the devicemapper storage driver. It is
 located in the
 <a href="https://github.com/docker/docker/tree/master/daemon/graphdriver/devmapper">Repository</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[DateTime conversion can be tricky]]></title>
    <link href="http://www.dbrunner.de/blog/2014/07/24/datetime-conversion-can-be-tricky/"/>
    <updated>2014-07-24T09:41:36+00:00</updated>
    <id>http://www.dbrunner.de/blog/2014/07/24/datetime-conversion-can-be-tricky</id>
    <content type="html"><![CDATA[<p>I wrote a small Lisp application and a JavaScript client gets some
data from that application. All time stamps are returned as &ldquo;Lisp&rdquo;
time stamps, i.e. an integer with seconds where zero equals Jan 01
1900.</p>

<p>In the JS client the time stamp is then converted to JS time stamps,
i.e. millisconds where zero equals Jan 01 1970.</p>

<p>When testing the application I noticed that sometimes the displayed
date is one day behind. For example in the data base I have Jan 05
1980 but in JavaScript I get a Jan 04 1980. But some other dates
worked: A time stamp Jan 05 1970 was correctly converted to Jan 05
1970.</p>

<p>I had a look into the JavaScript code and found:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>convA = function(ts) {
</span><span class='line'>  tmp = new Date(ts*1000);
</span><span class='line'>  tmp.setFullYear(tmp.getFullYear() - 70);
</span><span class='line'>  return tmp.getTime();
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>It&rsquo;s likely the developer thought: &ldquo;Well, it&rsquo;s millisecond instead of
second. Therefore I multiply by 1,000. But then I am 70 years in the
future and I have to substract 70 years and everything will be ok.&rdquo;</p>

<p>After thinking a while I came to the conclusion: Of course not!</p>

<p>The developer made the assumption that there are as many leap years
between 1900 and 1970 as between <code>ts</code> and <code>ts+70</code>. Obviously that
assumption does not hold for all time stamps. And therefore sometimes
the resulting JavaScript date is one day behind.</p>

<p>So a better solution would be to substract all seconds between 1900
and 1970 from <code>ts</code>, multiply by 1,000 and treat this as a JavaScript
time stamp. Perhaps best would be to do the conversion in the Lisp
process and only deliver a JavaScript-like time stamp.</p>
]]></content>
  </entry>
  
</feed>
